---
title: "Modelling Flow"
author: "Matthew Ross"
date: "2024-04-24"
output: html_document
---

```{r setup, include=FALSE}

library(tidyverse)
knitr::opts_chunk$set(echo = TRUE)


create_plot <- function(x, y){
  ggplot(all_vars, aes(x = .data[[x]], y = .data[[y]])) +
    geom_point()+
    geom_smooth(method = "lm", se = F)
}


# Pull in data

dat_files <- list.files('data',
                        full.names = T)



climate <- read_delim(dat_files[1], delim = ';')

hydro <- read_delim('data/hydro.txt', delim = ';')

soil <- read_delim('data/soil.txt', delim = ';')

topo <- read_delim('data/topo.txt', delim = ';')

all_vars <- inner_join(climate, hydro, by = 'gauge_id')%>%
  left_join( soil, by = 'gauge_id')%>%
  left_join(topo, by = "gauge_id")
```

# Modelling Flow

Now that we have explored individual correlations between long-term flow characteristics and potential drivers of those characteristics (climate, soils, etc...), we can start to build out increasingly complex models to predict flow characteristics.

# Assignment

## Build a parsimonious linear model

Pick one of the flow characteristics that mosts interests you and use the `lm` function to build a parsimonious model that predicts your favorite characteristic. What is parsimony? It's a model that is complex enough to capture the major controls, but simple enough to be understandable. You will need to explore, read, understand the differences between a + sign interaction, a ":" interaction and a \* interaction in `lm` terminology.

Please report your R2, slope estimates, and p-value of your model and write out your interpretation of these numbers.

```{r}

# Variable to predict q_mean
# Probably some function of p_mean, runoff_ratio,  area_gages2, "p_mean", 'q95', 'q5', 'low_prec_freq'

vars <- c('p_mean', 'runoff_ratio', 'area_gages2')
list_p <- map2(.x = "q_mean", .y = vars , create_plot)
ggpubr::ggarrange(plotlist = list_p)

# probably want to log area_gages2?

ggplot(all_vars, aes(x = q_mean, y = log((p_mean*runoff_ratio)/area_gages2))) +
    geom_point()+
    geom_smooth(method = "lm", se = F)

ggplot(all_vars, aes(x = p_mean*q95 , y = q_mean ))+
  geom_point()+
  scale_y_log10()+
  geom_smooth(method = "lm", se = F)



# Remove rows with missing values
concise <- na.omit(all_vars)%>%
  select(gauge_id,p_mean, q95, q_mean, area_gages2,runoff_ratio, p_seasonality)%>%
  filter(p_mean != 0 & q95 != 0 )

#log to get a linear relationship
ggplot(concise, aes(x = (p_mean*log10(q95)*runoff_ratio)/log10(area_gages2) , y = q_mean))+
  geom_point()+
  geom_smooth(method = "lm", se = F)

# Fit the linear regression model
model <- lm(q_mean ~ (p_mean:runoff_ratio)*log10(area_gages2) , data = concise)
summary(model)

preds <- concise%>%
  mutate(q_mean_preds = predict(model, newdata = .))

```

Initially I thought 'q5', 'low_prec_freq' would be helpful to add to the linear model of q_mean but ultimately so much of q_mean is decided by the relationship between p_mean and runoff ratio. This makes sense since runoff ratio is just the relationship between stream flow generated by precipitation. I tried to improve this by adding in watershed area to hopefully account for outliers both on the small and large size. This got slightly better by putting WS area in log scale but maybe didn't improve it drastically. \
\
When I did the model "lm(q_mean \~ (p_mean:runoff_ratio)\*log10(area_gages2)", I got a R2 of 1 which seems maybe incorrect since it shouldn't have a perfect relationship?

## Build a CART model to predict flow.

Linear models help us both predict and understand drivers of change, machine learning can help us understand drivers of change, but as a technique it is more suited to accurate predictions. CART or Classification and Regression Trees are a nice intermediate between lms and ml. Tons of resources for this but [CART Logic](https://koalaverse.github.io/machine-learning-in-R/decision-trees.html#cart-software-in-r), provides a good conceptual overview, and [CART demo](https://www.statmethods.net/advstats/cart.html) provides a good enough code demo.

Read the logic intro above, and the code demo as well, to build a CART model version of your lm. Use the code to visualize your CART output.

```{r}
library(rpart)

# Regression Example

# # grow tree
# fit <- rpart(Mileage~Price + Country + Reliability + Type,
#    method="anova", data=cu.summary)
# 
# printcp(fit) # display the results
# plotcp(fit) # visualize cross-validation results
# summary(fit) # detailed summary of splits
# 
# # create additional plots
# par(mfrow=c(1,2)) # two plots on one page
# rsq.rpart(fit) # visualize cross-validation results
# 
# # plot tree
# plot(fit, uniform=TRUE,
#    main="Regression Tree for Mileage ")
# text(fit, use.n=TRUE, all=TRUE, cex=.8)


fit_q_mean <- rpart(q_mean ~ area_gages2 + runoff_ratio + p_mean + p_seasonality  , method = "anova",  data = concise)
printcp(fit_q_mean) # display the results
plotcp(fit_q_mean) # visualize cross-validation results
summary(fit_q_mean) # detailed summary of splits
# plot tree
plot(fit_q_mean, uniform=TRUE,
   main="Regression Tree for q_mean ")
text(fit_q_mean, use.n=TRUE, all=TRUE, cex=.8)

```
 I made a model of q mean using the variables area_gages2, runoff_ratio, p_mean, and p_seasonality. I figured I would try to also throw in p_seasonality since it might indicate if the precip is in phase with ET or not? After 8 branches, the relative error is 0.099. I dont really understand if this is good or not or really how to test the model to make it better?



## Build a RandomForest

CARTs are a single tree, what if we had thousands? Would we get better performance (yes!)

The same CART logic site above introduces random forests as well. Please read this part of the site and use the code demo to build your own RandomForest. Remember, for a RandomForest type model we want to make sure we split our data at least into train and test datasets and ideally into train-test-val.

```{r}

library(randomForest)
random_forest <- randomForest(q_mean ~ area_gages2 + runoff_ratio + p_mean + p_seasonality, data = concise)
print(random_forest) # view results
importance(random_forest)

random_forest2 <- randomForest(q_mean ~ runoff_ratio + p_mean + p_seasonality, data = concise)
print(random_forest2) # view results
importance(random_forest2)


```

The results of this model made slightly more sense! It appears that area is maybe less significant for modeling p_mean than I had thought based on the results from the `importance` function. Re did the model without WS area and MSresidals decreased by half. 

